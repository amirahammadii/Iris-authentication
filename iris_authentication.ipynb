{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39bf085b",
      "metadata": {
        "id": "39bf085b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POcvL8Qit52_",
        "outputId": "7eeaf265-b4b8-4c80-83e9-59cf32c3fd68"
      },
      "id": "POcvL8Qit52_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f1124d",
      "metadata": {
        "id": "c7f1124d"
      },
      "outputs": [],
      "source": [
        "# Define the path to the dataset folder\n",
        "dataset_path = \"/content/drive/MyDrive/MMU-Iris-Database\"\n",
        "data_path = \"/content/drive/MyDrive/AMF Iris Dataset\"\n",
        "casia_path = \"/content/drive/MyDrive/casia-iris-syc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9502310a",
      "metadata": {
        "id": "9502310a"
      },
      "outputs": [],
      "source": [
        "# Initialize lists to store images and labels\n",
        "images = []\n",
        "person_labels = []\n",
        "test_data = []\n",
        "test_person_label = []\n",
        "\n",
        "img_dim = {'width': 225, 'height': 225}\n",
        "\n",
        "i = 1\n",
        "person_id = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f227bd6",
      "metadata": {
        "id": "5f227bd6",
        "outputId": "35caaf5a-447a-48eb-8cee-287804de9b56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total of Original images: 360\n",
            "Total of test data (20% original data): 90\n",
            "test_labesl [0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23, 24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 32, 32, 33, 33, 34, 34, 35, 35, 36, 36, 37, 37, 38, 38, 39, 39, 40, 40, 41, 41, 42, 42, 43, 43, 44, 44]\n"
          ]
        }
      ],
      "source": [
        "# Loop through each person's folder\n",
        "for person_folder in os.listdir(dataset_path):\n",
        "    if('.txt' in person_folder): continue\n",
        "\n",
        "    for eye_side_folder in os.listdir(os.path.join(dataset_path, person_folder)):\n",
        "        eye_side = 0 if eye_side_folder == \"left\" else 1 # Assign labels for left (0) and right (1)\n",
        "        for image_filename in os.listdir(os.path.join(dataset_path, person_folder, eye_side_folder)):\n",
        "            if('.db' in image_filename): continue\n",
        "            image_path = os.path.join(dataset_path, person_folder, eye_side_folder, image_filename)\n",
        "\n",
        "            # Load and preprocess the image\n",
        "            img = cv2.imread(image_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB) # Convert to grayscale (if not already)\n",
        "            img = cv2.resize(img, (img_dim['width'], img_dim['height'])) # Resize to a common size\n",
        "\n",
        "            img = img / 255.0\n",
        "\n",
        "            if i % 5 == 0:\n",
        "                test_data.append(img)\n",
        "                test_person_label.append(person_id)\n",
        "\n",
        "            else:\n",
        "                images.append(img)\n",
        "                person_labels.append(person_id)\n",
        "\n",
        "            i += 1\n",
        "    person_id += 1\n",
        "\n",
        "\n",
        "print('Total of Original images:', len(images))\n",
        "print('Total of test data (20% original data):', len(test_data))\n",
        "print('test_labesl', test_person_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d48f00c",
      "metadata": {
        "scrolled": true,
        "id": "7d48f00c",
        "outputId": "1de7996d-a82b-48ae-b2dd-ad34a960fa9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total of Original images: 792\n",
            "Total of test data (20% original data): 198\n",
            "test_labesl [0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23, 24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 32, 32, 33, 33, 34, 34, 35, 35, 36, 36, 37, 37, 38, 38, 39, 39, 40, 40, 41, 41, 42, 42, 43, 43, 44, 44, 45, 45, 46, 46, 47, 47, 48, 48, 49, 49, 50, 50, 51, 51, 52, 52, 53, 53, 54, 54, 55, 55, 56, 56, 57, 57, 58, 58, 59, 59, 60, 60, 61, 61, 62, 62, 63, 63, 64, 64, 65, 65, 66, 66, 67, 67, 68, 68, 69, 69, 70, 70, 71, 71, 72, 72, 73, 73, 74, 74, 75, 75, 76, 76, 77, 77, 78, 78, 79, 79, 80, 80, 81, 81, 82, 82, 83, 83, 84, 84, 85, 85, 86, 86, 87, 87, 88, 88, 89, 89, 90, 90, 91, 91, 92, 92, 93, 93, 94, 94, 95, 95, 96, 96, 97, 97, 98, 98]\n",
            "990\n"
          ]
        }
      ],
      "source": [
        "# Loop through each person's folder\n",
        "for person_folder in os.listdir(data_path):\n",
        "    if('.txt' in person_folder): continue\n",
        "\n",
        "    for image_filename in os.listdir(os.path.join(data_path, person_folder)):\n",
        "            if('.db' in image_filename): continue\n",
        "            image_path = os.path.join(data_path, person_folder, image_filename)\n",
        "\n",
        "            # Load and preprocess the image\n",
        "            img = cv2.imread(image_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB) # Convert to grayscale (if not already)\n",
        "            img = cv2.resize(img, (img_dim['width'], img_dim['height'])) # Resize to a common size\n",
        "\n",
        "            img = img / 255.0\n",
        "\n",
        "            if i % 5 == 0:\n",
        "                test_data.append(img)\n",
        "                test_person_label.append(person_id)\n",
        "\n",
        "            else:\n",
        "                images.append(img)\n",
        "                person_labels.append(person_id)\n",
        "\n",
        "            i += 1\n",
        "    person_id += 1\n",
        "\n",
        "\n",
        "print('Total of Original images:', len(images))\n",
        "print('Total of test data (20% original data):', len(test_data))\n",
        "print('test_labesl', test_person_label)\n",
        "print(len(test_person_label)+len(person_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f657f2af",
      "metadata": {
        "id": "f657f2af"
      },
      "outputs": [],
      "source": [
        "images = np.array(images ,  dtype= 'float32')\n",
        "person_labels = np.array(person_labels)\n",
        "test_data = np.array(test_data , dtype= 'float32')\n",
        "test_person_label = np.array(test_person_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bf6a998",
      "metadata": {
        "id": "6bf6a998",
        "outputId": "4c49cda6-f46e-48d6-aa6a-a4084fd9d983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/77\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\windos 10\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:5729: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 82s 3s/step - loss: 4.6367 - accuracy: 0.0215 - val_loss: 4.2788 - val_accuracy: 0.1111\n",
            "Epoch 2/77\n",
            "25/25 [==============================] - 79s 3s/step - loss: 3.5991 - accuracy: 0.1894 - val_loss: 2.2289 - val_accuracy: 0.4848\n",
            "Epoch 3/77\n",
            "25/25 [==============================] - 80s 3s/step - loss: 1.5573 - accuracy: 0.6162 - val_loss: 1.4003 - val_accuracy: 0.7273\n",
            "Epoch 4/77\n",
            "25/25 [==============================] - 84s 3s/step - loss: 0.6264 - accuracy: 0.8434 - val_loss: 1.2720 - val_accuracy: 0.7626\n",
            "Epoch 5/77\n",
            "25/25 [==============================] - 80s 3s/step - loss: 0.2288 - accuracy: 0.9343 - val_loss: 1.0118 - val_accuracy: 0.8081\n",
            "Epoch 6/77\n",
            "25/25 [==============================] - 78s 3s/step - loss: 0.1457 - accuracy: 0.9545 - val_loss: 1.0688 - val_accuracy: 0.7727\n",
            "Epoch 7/77\n",
            "25/25 [==============================] - 79s 3s/step - loss: 0.1231 - accuracy: 0.9760 - val_loss: 1.3964 - val_accuracy: 0.7677\n",
            "Epoch 8/77\n",
            "25/25 [==============================] - 92s 4s/step - loss: 0.0802 - accuracy: 0.9747 - val_loss: 2.2797 - val_accuracy: 0.7677\n",
            "Epoch 9/77\n",
            "25/25 [==============================] - 95s 4s/step - loss: 0.0357 - accuracy: 0.9937 - val_loss: 1.1659 - val_accuracy: 0.8081\n",
            "Epoch 10/77\n",
            "25/25 [==============================] - 96s 4s/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 1.2936 - val_accuracy: 0.8131\n",
            "Epoch 11/77\n",
            "25/25 [==============================] - 95s 4s/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 1.2293 - val_accuracy: 0.8485\n",
            "Epoch 12/77\n",
            "25/25 [==============================] - 95s 4s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5544 - val_accuracy: 0.8232\n",
            "Epoch 13/77\n",
            "25/25 [==============================] - 96s 4s/step - loss: 4.5957e-04 - accuracy: 1.0000 - val_loss: 1.5925 - val_accuracy: 0.8232\n",
            "Epoch 14/77\n",
            "25/25 [==============================] - 14350s 598s/step - loss: 1.1166e-04 - accuracy: 1.0000 - val_loss: 1.5746 - val_accuracy: 0.8182\n",
            "Epoch 15/77\n",
            "25/25 [==============================] - 90s 4s/step - loss: 6.7231e-05 - accuracy: 1.0000 - val_loss: 1.6147 - val_accuracy: 0.8182\n",
            "Epoch 16/77\n",
            "25/25 [==============================] - 95s 4s/step - loss: 4.5597e-05 - accuracy: 1.0000 - val_loss: 1.6564 - val_accuracy: 0.8232\n",
            "Epoch 17/77\n",
            "25/25 [==============================] - 95s 4s/step - loss: 3.5500e-05 - accuracy: 1.0000 - val_loss: 1.6667 - val_accuracy: 0.8283\n",
            "Epoch 18/77\n",
            "25/25 [==============================] - 95s 4s/step - loss: 2.9178e-05 - accuracy: 1.0000 - val_loss: 1.6799 - val_accuracy: 0.8333\n",
            "Epoch 19/77\n",
            "25/25 [==============================] - 96s 4s/step - loss: 2.4215e-05 - accuracy: 1.0000 - val_loss: 1.6862 - val_accuracy: 0.8333\n",
            "Epoch 20/77\n",
            "25/25 [==============================] - 95s 4s/step - loss: 2.0511e-05 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.8333\n",
            "Epoch 21/77\n",
            "25/25 [==============================] - 97s 4s/step - loss: 1.7280e-05 - accuracy: 1.0000 - val_loss: 1.7118 - val_accuracy: 0.8333\n",
            "Epoch 22/77\n",
            "25/25 [==============================] - 97s 4s/step - loss: 1.4641e-05 - accuracy: 1.0000 - val_loss: 1.7237 - val_accuracy: 0.8333\n",
            "Epoch 23/77\n",
            "25/25 [==============================] - 95s 4s/step - loss: 1.2481e-05 - accuracy: 1.0000 - val_loss: 1.7335 - val_accuracy: 0.8333\n",
            "Epoch 24/77\n",
            "25/25 [==============================] - 98s 4s/step - loss: 1.0689e-05 - accuracy: 1.0000 - val_loss: 1.7464 - val_accuracy: 0.8384\n",
            "Epoch 25/77\n",
            "25/25 [==============================] - 95s 4s/step - loss: 9.3067e-06 - accuracy: 1.0000 - val_loss: 1.7595 - val_accuracy: 0.8384\n",
            "Epoch 26/77\n",
            "25/25 [==============================] - 95s 4s/step - loss: 8.1197e-06 - accuracy: 1.0000 - val_loss: 1.7696 - val_accuracy: 0.8384\n",
            "Epoch 27/77\n",
            "25/25 [==============================] - 97s 4s/step - loss: 7.0913e-06 - accuracy: 1.0000 - val_loss: 1.7812 - val_accuracy: 0.8384\n",
            "Epoch 28/77\n",
            "25/25 [==============================] - 96s 4s/step - loss: 6.3185e-06 - accuracy: 1.0000 - val_loss: 1.7875 - val_accuracy: 0.8434\n",
            "Epoch 29/77\n",
            "25/25 [==============================] - 96s 4s/step - loss: 5.6582e-06 - accuracy: 1.0000 - val_loss: 1.8015 - val_accuracy: 0.8434\n",
            "Epoch 30/77\n",
            "25/25 [==============================] - 97s 4s/step - loss: 5.1267e-06 - accuracy: 1.0000 - val_loss: 1.8116 - val_accuracy: 0.8434\n",
            "Epoch 31/77\n",
            "25/25 [==============================] - 96s 4s/step - loss: 4.6585e-06 - accuracy: 1.0000 - val_loss: 1.8244 - val_accuracy: 0.8434\n",
            "Epoch 32/77\n",
            "25/25 [==============================] - 96s 4s/step - loss: 4.2682e-06 - accuracy: 1.0000 - val_loss: 1.8293 - val_accuracy: 0.8434\n",
            "Epoch 33/77\n",
            "25/25 [==============================] - 96s 4s/step - loss: 3.9194e-06 - accuracy: 1.0000 - val_loss: 1.8378 - val_accuracy: 0.8434\n",
            "Epoch 34/77\n",
            "25/25 [==============================] - 97s 4s/step - loss: 3.6281e-06 - accuracy: 1.0000 - val_loss: 1.8464 - val_accuracy: 0.8434\n",
            "Epoch 35/77\n",
            "25/25 [==============================] - 96s 4s/step - loss: 3.3492e-06 - accuracy: 1.0000 - val_loss: 1.8550 - val_accuracy: 0.8434\n",
            "Epoch 36/77\n",
            "25/25 [==============================] - 96s 4s/step - loss: 3.1182e-06 - accuracy: 1.0000 - val_loss: 1.8585 - val_accuracy: 0.8434\n",
            "Epoch 37/77\n",
            "25/25 [==============================] - 97s 4s/step - loss: 2.9140e-06 - accuracy: 1.0000 - val_loss: 1.8644 - val_accuracy: 0.8434\n",
            "Epoch 38/77\n",
            "25/25 [==============================] - 100s 4s/step - loss: 2.7302e-06 - accuracy: 1.0000 - val_loss: 1.8723 - val_accuracy: 0.8434\n",
            "Epoch 39/77\n",
            "25/25 [==============================] - 109s 4s/step - loss: 2.5625e-06 - accuracy: 1.0000 - val_loss: 1.8790 - val_accuracy: 0.8434\n",
            "Epoch 40/77\n",
            "25/25 [==============================] - 115s 5s/step - loss: 2.4242e-06 - accuracy: 1.0000 - val_loss: 1.8837 - val_accuracy: 0.8384\n",
            "Epoch 41/77\n",
            "25/25 [==============================] - 101s 4s/step - loss: 2.2795e-06 - accuracy: 1.0000 - val_loss: 1.8899 - val_accuracy: 0.8384\n",
            "Epoch 42/77\n",
            "25/25 [==============================] - 108s 4s/step - loss: 2.1516e-06 - accuracy: 1.0000 - val_loss: 1.8958 - val_accuracy: 0.8384\n",
            "Epoch 43/77\n",
            "25/25 [==============================] - 105s 4s/step - loss: 2.0354e-06 - accuracy: 1.0000 - val_loss: 1.9014 - val_accuracy: 0.8384\n",
            "Epoch 44/77\n",
            "25/25 [==============================] - 108s 4s/step - loss: 1.9245e-06 - accuracy: 1.0000 - val_loss: 1.9082 - val_accuracy: 0.8384\n",
            "Epoch 45/77\n",
            "25/25 [==============================] - 109s 4s/step - loss: 1.8288e-06 - accuracy: 1.0000 - val_loss: 1.9107 - val_accuracy: 0.8384\n",
            "Epoch 46/77\n",
            "25/25 [==============================] - 98s 4s/step - loss: 1.7302e-06 - accuracy: 1.0000 - val_loss: 1.9176 - val_accuracy: 0.8384\n",
            "Epoch 47/77\n",
            "25/25 [==============================] - 97s 4s/step - loss: 1.6397e-06 - accuracy: 1.0000 - val_loss: 1.9220 - val_accuracy: 0.8384\n",
            "Epoch 48/77\n",
            "25/25 [==============================] - 97s 4s/step - loss: 1.5488e-06 - accuracy: 1.0000 - val_loss: 1.9247 - val_accuracy: 0.8384\n",
            "Epoch 49/77\n",
            "25/25 [==============================] - 98s 4s/step - loss: 1.4621e-06 - accuracy: 1.0000 - val_loss: 1.9295 - val_accuracy: 0.8384\n",
            "Epoch 50/77\n",
            "25/25 [==============================] - 98s 4s/step - loss: 1.3704e-06 - accuracy: 1.0000 - val_loss: 1.9344 - val_accuracy: 0.8384\n",
            "Epoch 51/77\n",
            "25/25 [==============================] - 97s 4s/step - loss: 1.2762e-06 - accuracy: 1.0000 - val_loss: 1.9352 - val_accuracy: 0.8384\n",
            "Epoch 52/77\n",
            "25/25 [==============================] - 97s 4s/step - loss: 1.1727e-06 - accuracy: 1.0000 - val_loss: 1.9359 - val_accuracy: 0.8384\n",
            "Epoch 53/77\n",
            "25/25 [==============================] - 96s 4s/step - loss: 1.0632e-06 - accuracy: 1.0000 - val_loss: 1.9349 - val_accuracy: 0.8384\n",
            "Epoch 54/77\n",
            "25/25 [==============================] - 97s 4s/step - loss: 9.3485e-07 - accuracy: 1.0000 - val_loss: 1.9348 - val_accuracy: 0.8434\n",
            "Epoch 55/77\n",
            "25/25 [==============================] - 97s 4s/step - loss: 8.1444e-07 - accuracy: 1.0000 - val_loss: 1.9347 - val_accuracy: 0.8434\n",
            "Epoch 56/77\n",
            "25/25 [==============================] - 97s 4s/step - loss: 6.9794e-07 - accuracy: 1.0000 - val_loss: 1.9330 - val_accuracy: 0.8434\n",
            "Epoch 57/77\n",
            "25/25 [==============================] - 102s 4s/step - loss: 6.0778e-07 - accuracy: 1.0000 - val_loss: 1.9303 - val_accuracy: 0.8434\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58/77\n",
            "25/25 [==============================] - 111s 4s/step - loss: 5.2229e-07 - accuracy: 1.0000 - val_loss: 1.9313 - val_accuracy: 0.8434\n",
            "Epoch 59/77\n",
            "25/25 [==============================] - 103s 4s/step - loss: 4.6299e-07 - accuracy: 1.0000 - val_loss: 1.9315 - val_accuracy: 0.8434\n",
            "Epoch 60/77\n",
            "25/25 [==============================] - 106s 4s/step - loss: 4.1257e-07 - accuracy: 1.0000 - val_loss: 1.9365 - val_accuracy: 0.8434\n",
            "Epoch 61/77\n",
            "25/25 [==============================] - 20212s 842s/step - loss: 3.7012e-07 - accuracy: 1.0000 - val_loss: 1.9378 - val_accuracy: 0.8434\n",
            "Epoch 62/77\n",
            "25/25 [==============================] - 88s 4s/step - loss: 3.4167e-07 - accuracy: 1.0000 - val_loss: 1.9417 - val_accuracy: 0.8434\n",
            "Epoch 63/77\n",
            "25/25 [==============================] - 98s 4s/step - loss: 3.1067e-07 - accuracy: 1.0000 - val_loss: 1.9436 - val_accuracy: 0.8434\n",
            "Epoch 64/77\n",
            "25/25 [==============================] - 101s 4s/step - loss: 2.8824e-07 - accuracy: 1.0000 - val_loss: 1.9480 - val_accuracy: 0.8434\n",
            "Epoch 65/77\n",
            "25/25 [==============================] - 99s 4s/step - loss: 2.6897e-07 - accuracy: 1.0000 - val_loss: 1.9502 - val_accuracy: 0.8434\n",
            "Epoch 66/77\n",
            "25/25 [==============================] - 75s 3s/step - loss: 2.5136e-07 - accuracy: 1.0000 - val_loss: 1.9528 - val_accuracy: 0.8434\n",
            "Epoch 67/77\n",
            "25/25 [==============================] - 86s 3s/step - loss: 2.3736e-07 - accuracy: 1.0000 - val_loss: 1.9574 - val_accuracy: 0.8434\n",
            "Epoch 68/77\n",
            "25/25 [==============================] - 73s 3s/step - loss: 2.2126e-07 - accuracy: 1.0000 - val_loss: 1.9609 - val_accuracy: 0.8434\n",
            "Epoch 69/77\n",
            "25/25 [==============================] - 71s 3s/step - loss: 2.0741e-07 - accuracy: 1.0000 - val_loss: 1.9642 - val_accuracy: 0.8434\n",
            "Epoch 70/77\n",
            "25/25 [==============================] - 71s 3s/step - loss: 1.9387e-07 - accuracy: 1.0000 - val_loss: 1.9685 - val_accuracy: 0.8434\n",
            "Epoch 71/77\n",
            "25/25 [==============================] - 76s 3s/step - loss: 1.8574e-07 - accuracy: 1.0000 - val_loss: 1.9684 - val_accuracy: 0.8485\n",
            "Epoch 72/77\n",
            "25/25 [==============================] - 69s 3s/step - loss: 1.7385e-07 - accuracy: 1.0000 - val_loss: 1.9731 - val_accuracy: 0.8485\n",
            "Epoch 73/77\n",
            "25/25 [==============================] - 70s 3s/step - loss: 1.6451e-07 - accuracy: 1.0000 - val_loss: 1.9770 - val_accuracy: 0.8485\n",
            "Epoch 74/77\n",
            "25/25 [==============================] - 70s 3s/step - loss: 1.5684e-07 - accuracy: 1.0000 - val_loss: 1.9803 - val_accuracy: 0.8535\n",
            "Epoch 75/77\n",
            "25/25 [==============================] - 75s 3s/step - loss: 1.5112e-07 - accuracy: 1.0000 - val_loss: 1.9799 - val_accuracy: 0.8535\n",
            "Epoch 76/77\n",
            "25/25 [==============================] - 73s 3s/step - loss: 1.4224e-07 - accuracy: 1.0000 - val_loss: 1.9833 - val_accuracy: 0.8535\n",
            "Epoch 77/77\n",
            "25/25 [==============================] - 72s 3s/step - loss: 1.3637e-07 - accuracy: 1.0000 - val_loss: 1.9877 - val_accuracy: 0.8535\n",
            "7/7 - 4s - loss: 1.9877 - accuracy: 0.8535 - 4s/epoch - 516ms/step\n",
            "0.8535353541374207\n"
          ]
        }
      ],
      "source": [
        "#build cnn\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_dim['width'], img_dim['height'], 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(99, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "test_data = np.array(test_data)\n",
        "test_person_label = np.array(test_person_label)\n",
        "\n",
        "history = model.fit(images, person_labels, epochs=77  ,batch_size=32, validation_data=(test_data, test_person_label))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_data,  test_person_label, verbose=2)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "786e3fca",
      "metadata": {
        "id": "786e3fca",
        "outputId": "772f3750-3dd1-42a9-9c94-2c1d306faeee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8535353541374207\n",
            "7/7 [==============================] - 4s 503ms/step\n"
          ]
        }
      ],
      "source": [
        "print(test_acc)\n",
        "#print(test_person_label)\n",
        "predict = model.predict(test_data)\n",
        "predict = np.argmax(predict, axis = -1)\n",
        "#for i in test_person_label :\n",
        "    #print(i , test_person_label[i] == predict[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a9b2ece",
      "metadata": {
        "id": "5a9b2ece"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}